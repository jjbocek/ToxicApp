{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# A Toxic Comment Identifier Application - Main Notebook\n",
    "### DSC 478 - Winter 2023\n",
    "### Project Type: App Dev\n",
    "### Team Members: Jeff Bocek, Xuyang Ji, Anna-Lisa Vu\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from itertools import cycle\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "#from sklearn's...\n",
    "from sklearn.feature_extraction.text import CountVectorizer #Convert a collection of text documents to a matrix of token counts.\n",
    "from sklearn.feature_extraction.text import TfidfTransformer #Transform a count matrix to a normalized tf or tf-idf representation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #Convert a collection of raw documents to a matrix of TF-IDF features\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV #Cross validation gird search and training and testing chunks\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.decomposition import TruncatedSVD #Dimension Reduction (LSA)\n",
    "from sklearn.preprocessing import Normalizer, LabelBinarizer \n",
    "from sklearn.ensemble import VotingClassifier #to create ensemble model\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import RocCurveDisplay, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exploratory Analysis (Xuyang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#[Link to Toxic_App_Exploratory_Data_Cleaning]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Pre-processing of Data (Xuyang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#[Link to Toxic_App_Exploratory_Data_Cleaning]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Cleaned and Processed Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading subset of training data with percentage of original instances:  \n",
    "1% of non-toxic comments: 1433  \n",
    "10% of toxic comments: 1370 and  \n",
    "100% of severe toxic comments: 1595\n",
    "\n",
    "Loading subset of testing data with percentage of original instances:  \n",
    "1% of non-toxic comments: 577  \n",
    "10% of toxic comments: 572 and   \n",
    "100% of severe toxic comments: 367"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_object = open('clean_data1.p', 'rb')\n",
    "clean_data = pickle.load(file_object)\n",
    "file_object.close()\n",
    "train = clean_data[0]\n",
    "test = clean_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balanced training data\n",
    "train_df_subset1 = train['comment_text']\n",
    "train_lab_subset1 = train['toxicity_level']\n",
    "\n",
    "#testing data\n",
    "test_df_subset1 = test['comment_text']\n",
    "test_lab_subset1 = test['toxicity_level']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading **uneven** subset of training data with percentage of original instances:  \n",
    "1% of non-toxic comments: 1433  \n",
    "20% of toxic comments: 2740 and  \n",
    "100% of severe toxic comments: 1595"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_object = open('clean_data_unbalanced.p', 'rb')\n",
    "clean_data = pickle.load(file_object)\n",
    "file_object.close()\n",
    "train = clean_data[0]\n",
    "test = clean_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unbalanced training data\n",
    "train_df_subsetU = train['comment_text']\n",
    "train_lab_subsetU = train['toxicity_level']\n",
    "\n",
    "#testing data\n",
    "test_df_subsetU = test['comment_text']\n",
    "test_lab_subsetU = test['toxicity_level']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Transformation (Lisa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#[Link to Toxic_App_Transformation notebook (if needed)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Term Frequencies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply put, the weights in the matrix represent the frequency of the term in a specific comment. The underlying concept is the higher the term frequency for a specific term in a comment, the more important it is for that comment. We use scikit-learn’s CountVectorizer(). Tuning occurred by adjusting the ‘max_df’ and ‘min_df’ which when building the vocabulary ignore terms that have a document frequency higher/lower respectively than the given threshold."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### TF*IDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Frequency - Inverse Document Frequency assesses how important a term is within a comment relative to our collection of comments. It does this by vectorizing and scoring a term by multiplying the term’s Term Frequency (TF; number of times the term appears in the comment over the total number of terms in the comment)  by the Inverse Document Frequency (IDF; the log of; the total number of comments over the total number of comments which contain the specific term plus one). By using this formula we don’t place added importance on the super common words which overshadow less common words which can show more meaning to the comments. We used scikit-learn’s TfidfVectorizer() to transform our preprocessed collection of comments into a TF-IDF matrix. In aberration to the basic formula referenced above TfidfVectorizer() adds a “+1” to the numerator and denominator of the IDF score to prevent zero divisions when the term is not present to better represent the IDF scores for sparse matrices. We tuned this transformation by trying two methods of normalization; ‘l1’ and ‘l2’. ‘l1’  normalized by using the sum of the absolute values of the vector elements is 1 while ‘l2’ is the Euclidean norm and the sum of squares of vector elements is 1. For ‘l2’ the cosine similarity between two vectors is their dot product. As was the case with Term Frequency tuning, tuned by adjusting the ‘max_df’ and ‘min_df’ which when building the vocabulary ignore terms that have a document frequency higher/lower respectively than the given threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def TFIDF_func(data):\n",
    "    vectorizer= TfidfVectorizer(smooth_idf=True, sublinear_tf=False, norm=None, \n",
    "                         analyzer='word')\n",
    "    txt_fitted= vectorizer.fit(data)\n",
    "    txt_tranformed = txt_fitted.transform(data) \n",
    "    X_tfidf= txt_tranformed.toarray()\n",
    "    terms= txt_fitted.get_feature_names_out()\n",
    "    return X_tfidf, terms\n",
    "\n",
    "X_tfidf, terms= TFIDF_func(train['comment_text'])\n",
    "X_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Doc2Vec (Lisa)\n",
    "Doc2Vec is a natural language processing technique that transforms a set of documents into a list of vectors. It is closely related to the Word2Vec; but is considered a more generalized form of it.  To best understand Doc2Vec, it is important to understand Word2Vec.  In Word2Vec, the algorithm looks at the context of each word and what other words surround it.  It assigns a numerical number to the word which represents the meaning of the word in its given context.  For example, if words \"Paris\" and \"France\" are in the same sentence, Word2Vec will create a number for each of these words which would represent that these 2 words are related.  This is exact same example is referenced in this article: https://medium.com/wisio/a-gentle-introduction-to-doc2vec-db3e8c0cce5e  Doc2Vec on the other hand generalized this technique.  Instead of having a numeric representation for the words, with Doc2Vec you can achieve a numeric representation for a document as a whole.\n",
    "\n",
    "We thought it would be a good exercise to use this data transformation technique in our project.  Each comment can be like a document.  To create the Doc2Vec vectors, we used the doc2Vec library package from the gensim.models library.  We ran this against the train and test data and feed that into our models.\n",
    "\n",
    "In the attached notebook are central methods we created so that we can get a doc2vec vector for the train and test data.  Using these methods each team member was able to feed a doc2vec transformed data set into the models.  Analysis and Evaluations of our the models performed with the data set is explained in the upcoming sections.\n",
    "\n",
    "Link to Doc2Vec Notebook: [Toxic_App_Doc2Vec.ipynb](Toxic_App_Doc2Vec.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dm': 0, 'vector_size': 500, 'window': 2, 'hs': 1, 'negative': 0}, {'dm': 0, 'vector_size': 500, 'window': 5, 'hs': 1, 'negative': 0}, {'dm': 0, 'vector_size': 1000, 'window': 2, 'hs': 1, 'negative': 0}, {'dm': 0, 'vector_size': 1000, 'window': 5, 'hs': 1, 'negative': 0}, {'dm': 1, 'vector_size': 500, 'window': 2, 'hs': 1, 'negative': 0}, {'dm': 1, 'vector_size': 500, 'window': 5, 'hs': 1, 'negative': 0}, {'dm': 1, 'vector_size': 1000, 'window': 2, 'hs': 1, 'negative': 0}, {'dm': 1, 'vector_size': 1000, 'window': 5, 'hs': 1, 'negative': 0}]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import doc2vec\n",
    "%run Toxic_App_Doc2Vec.ipynb\n",
    "d2v_model = doc2vec.Doc2Vec(vector_size = 1000, min_count = 5, epochs = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced training set\n",
    "d2v_model = doc2vec.Doc2Vec(vector_size = 1000, min_count = 5, epochs = 40)\n",
    "train_vectors1 = get_doc2vec_vectors(d2v_model, train_df_subset1)\n",
    "tokenized_test_comments = tokenize_comments(test_df_subset1)\n",
    "test_vectors1 = infer_vectors(d2v_model, tokenized_test_comments, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unbalanced training set\n",
    "d2v_model = doc2vec.Doc2Vec(vector_size = 1000, min_count = 5, epochs = 40)\n",
    "train_vectorsU = get_doc2vec_vectors(d2v_model, train_df_subsetU)\n",
    "tokenized_test_comments = tokenize_comments(test_df_subsetU)\n",
    "test_vectorsU = infer_vectors(d2v_model, tokenized_test_comments, \"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = {\n",
    "    # [X_train, y_train, X_test, y_test]\n",
    "    'balanced': [train_df_subset1, train_lab_subset1, test_df_subset1, test_lab_subset1],\n",
    "        # balanced training data with ratios 0.01, 0.10, 1.0\n",
    "    'balanced_D2V': [train_vectors1, train_lab_subset1, test_vectors1, test_lab_subset1],\n",
    "        # using Doc2Vec vectors\n",
    "    'unbalanced': [train_df_subsetU, train_lab_subsetU, test_df_subsetU, test_lab_subsetU],\n",
    "        # unbalanced training data with ratios 0.01, 0.20, 1.0\n",
    "    'unbalanced_D2V': [train_vectorsU, train_lab_subsetU, test_vectorsU, test_lab_subsetU],\n",
    "        # using Doc2Vec vectors\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Supervised Modeling & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tuning and model evaluation functions\n",
    "%run Toxic_App_Tuning_&_Evaluation_funcs.ipynb\n",
    "pipe_param_dict = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression as the Benchmark\n",
    "\n",
    "The baseline model is a Logistic Regression model fit to tf-idf vectorized comment text with using only words for tokens, with the target value being toxicity_level. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Gradiant Descent/Logistic Regression as the Baseline Model \n",
    "skf= StratifiedKFold(n_splits=5,shuffle=True,random_state=961)\n",
    "target= np.array(train['toxicity_level'])\n",
    "w=[]\n",
    "#loop through the value for svd dimension parameter\n",
    "for n in range(110,100,-1): #negative step to let range decrease from start\n",
    "    log=[]\n",
    "    for train_index, test_index in skf.split(X_tfidf,target):\n",
    "        xTrain, xTest= X_tfidf[train_index,:],X_tfidf[test_index,:]\n",
    "        yTrain,yTest= target[train_index],target[test_index]\n",
    "        lsa= make_pipeline(TruncatedSVD(n_components=n), Normalizer(copy=False))\n",
    "        xTrain_lsa= lsa.fit_transform(xTrain)\n",
    "        xTest_lsa= lsa.transform(xTest)    \n",
    "        explainedVar = lsa[0].explained_variance_ratio_.sum()\n",
    "        sdg_params = { \n",
    "            'loss': ['log','hinge','modified_huber'], \n",
    "            'penalty': ['l2','elasticnet'],\n",
    "            \"alpha\" : [0.0001, 0.001, 0.01, 0.1],\n",
    "            'n_jobs': [-1]\n",
    "            }\n",
    "        model= SGDClassifier(max_iter= 3000,random_state=961)\n",
    "        grid= GridSearchCV(model, param_grid=sdg_params,cv=5)\n",
    "        grid.fit(xTrain_lsa,yTrain)\n",
    "        #model= LogisticRegression(solver='lbfgs',multi_class=\"multinomial\").fit(xTrain_lsa,yTrain)\n",
    "\n",
    "        BModel= SGDClassifier(**grid.best_params_, max_iter= 3000,random_state=961)\n",
    "        BModel.fit(xTrain_lsa,yTrain)\n",
    "\n",
    "        f1Train= f1_score(yTrain,BModel.predict(xTrain_lsa),average='micro')\n",
    "        f1Test= f1_score(yTest,BModel.predict(xTest_lsa),average='micro') \n",
    "        AccTest= accuracy_score(yTest,BModel.predict(xTest_lsa))\n",
    "        log.append([f1Train,f1Test,AccTest])\n",
    "    print(\"For n_component= %r with explained variance = %r,the best parameters are: %r\"%(n, explainedVar,grid.best_params_))\n",
    "    \n",
    "    mean= np.mean(log,axis=0)\n",
    "    F1_train= mean[0]\n",
    "    F1_test= mean[1]\n",
    "    Accu_Test= mean[2]\n",
    "\n",
    "    w.append([n,F1_train, F1_test, Accu_Test])  \n",
    "svd_dm= pd.DataFrame(w,columns=['N',\"F1_Train\",\"F1_Test\",\"Accuracy _Test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svd_dm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/c4/lz0fty3s6b3148w_cbvkndwm0000gn/T/ipykernel_4785/1737570607.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m kwargs = dict (linestyle='dashed', linewidth=1.2,marker='o',\n\u001B[1;32m      2\u001B[0m                markerfacecolor='blue', markersize=3)\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mline_plot\u001B[0m\u001B[0;34m=\u001B[0m \u001B[0msvd_dm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"N\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mfigsize\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m7\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0mline_plot\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_title\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'LSA Dimension Parameter v/s SGD Logistic Regression'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mline_plot\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgrid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'svd_dm' is not defined"
     ]
    }
   ],
   "source": [
    "kwargs = dict (linestyle='dashed', linewidth=1.2,marker='o',\n",
    "               markerfacecolor='blue', markersize=3)\n",
    "line_plot= svd_dm.plot(x=\"N\",figsize=(7,3),**kwargs)\n",
    "line_plot.set_title('LSA Dimension Parameter v/s SGD Logistic Regression')\n",
    "line_plot.grid()\n",
    "line_plot.set_xlabel('N_components')\n",
    "line_plot.set_ylabel('F1_score/Accuracy')\n",
    "plt.show()\n",
    "bestN= svd_dm[svd_dm.index==svd_dm['F1_Test'].argmax()]\n",
    "bestN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Unsupervised Model to ensure data quality - K-Means Clustering \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### KMean\n",
    "lsa= make_pipeline(TruncatedSVD(n_components=110), Normalizer(copy=False))\n",
    "XLSA= lsa.fit_transform(X_tfidf)\n",
    "log = [] \n",
    "k_range = range(2,8) # Range of k values\n",
    "\n",
    "for k in k_range:\n",
    "    kmean = KMeans(n_clusters = k, random_state=961)\n",
    "    clusterLabel = kmean.fit_predict(XLSA)\n",
    "    inertia= kmean.inertia_\n",
    "    centroids= kmean.cluster_centers_\n",
    "    if True: # Generate Silhoettes Score\n",
    "        silhoettes_avg = silhouette_score(XLSA, clusterLabel)\n",
    "        log.append([k, inertia, silhoettes_avg])\n",
    "        continue\n",
    "    log.append([k, inertia])\n",
    "\n",
    "plot_df = pd.DataFrame(\n",
    "    log, columns = [\n",
    "        'k', 'Inertias (Sum of squared distances to Nearest Cluster Centroids)', 'Silhouette Coefficient'\n",
    "        ]\n",
    "    )\n",
    "fig, axes = plt.subplots(1,2, figsize=(18,7))\n",
    "sns.lineplot(\n",
    "    x='k', y='Inertias (Sum of squared distances to Nearest Cluster Centroids)', \n",
    "    data = plot_df, marker= 'o', ax = axes[0])\n",
    "axes[0].set_title(\"Elbow Method (Inertia)\")\n",
    "sns.lineplot(x='k', y='Silhouette Coefficient', data=plot_df, marker='o', ax = axes[1])\n",
    "axes[1].set_title(\"Silhoettes Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette_analysis_with_pca(n_clusters,X):\n",
    "    \n",
    "    # K-Mean Clustering\n",
    "    kmean = KMeans(n_clusters = n_clusters, random_state=961)\n",
    "    clusterLabel = kmean.fit_predict(X)\n",
    "    centroids= kmean.cluster_centers_\n",
    "\n",
    "    # Compute Individual Silhoette Score\n",
    "    silhoettes_avg = silhouette_score(X, clusterLabel)\n",
    "\n",
    "    # Compute Average Silhoette Score\n",
    "    sample_silhouette_values = silhouette_samples(X, clusterLabel)\n",
    "     # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    ################################### Silhouette Plot #############################################\n",
    " \n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    y_lower = 10\n",
    "\n",
    "    # Assign colours for different cluster\n",
    "    for i in range(n_clusters):\n",
    "         # Aggregate the silhouette scores for samples belonging to\n",
    "         # cluster i, and sort them\n",
    "         ith_cluster_silhouette_values = sample_silhouette_values[clusterLabel == i]\n",
    "         ith_cluster_silhouette_values.sort()\n",
    "         size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "         y_upper = y_lower + size_cluster_i\n",
    "         color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "         ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                           0, ith_cluster_silhouette_values,\n",
    "                           facecolor=color, edgecolor=color, alpha=0.7)\n",
    "         \n",
    "         ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "         y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"Silhouette Plot for Clusters.\")\n",
    "    ax1.set_xlabel(\"Silhouette Coefficient Values\")\n",
    "    ax1.set_ylabel(\"Cluster Label\")\n",
    "    # avg sil score \n",
    "    ax1.axvline(x=silhoettes_avg, color=\"red\", linestyle=\"--\")\n",
    "    ax1.set_yticks([]) \n",
    "    ax1.set_xticks([-0.2, 0, 0.2, 0.4, 0.6, 0.8])\n",
    "\n",
    "    ################################### SVD Plot #############################################\n",
    " \n",
    "    # Compute tsvd with only First 2 Number of Component\n",
    "    tsvd2 = TruncatedSVD(n_components=2)\n",
    "    sample2 = tsvd2.fit_transform(X)\n",
    "\n",
    "    ##Getting diff color for diff cluster \n",
    "    colors = cm.nipy_spectral(clusterLabel.astype(float) / n_clusters)\n",
    "    ax2.scatter(sample2[:,0], sample2[:,1], marker='.', s=70, lw=0, alpha=1,\n",
    "            c=colors, edgecolor='k')\n",
    "\n",
    "    centers = centroids.dot(tsvd2.components_.T) # Cluster Positions after transformation \n",
    "    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                 c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "                    s=50, edgecolor='k')\n",
    "    ax2.set_title(\"The visualization of TSVD with total explained variance of {:.2f}%.\".format(tsvd2.explained_variance_ratio_.sum()*100))\n",
    "    ax2.set_xlabel(\"Feature space for the 1st component\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd component\")\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on Toxic Comment Dataset\"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, k in enumerate(range(3,5)): # Analyse k = (3,4)\n",
    "    silhouette_analysis_with_pca(n_clusters = k, X = XLSA)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go with k=3\n",
    "kmean3 = KMeans(n_clusters = 3, random_state=961)\n",
    "clusterLabel3 = kmean3.fit_predict(XLSA)\n",
    "centroids3= kmean3.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_space_centroids = lsa[0].inverse_transform(kmean3.cluster_centers_)\n",
    "order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "labels = train.toxicity_level\n",
    "unique_labels, category_sizes = np.unique(labels, return_counts=True)\n",
    "true_k = unique_labels.shape[0]\n",
    "\n",
    "for i in range(true_k):\n",
    "    print(f\"Cluster {i}: \", end=\"\")\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(f\"{terms[ind]} \", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confuM= confusion_matrix(labels,kmean3.labels_)\n",
    "sns.set()\n",
    "ax=sns.heatmap(confuM,annot=True,fmt=\"d\",cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Rocchio/Nearest Centroid (Lisa)\n",
    "\n",
    "Explanation goes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rocchio Pipeline\n",
    "pipe_Rocchio = Pipeline(\n",
    "    [\n",
    "        ('token_value', 'passthrough'),\n",
    "        ('reduce_dim', 'passthrough'),\n",
    "        ('clf', NearestCentroid())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Rocchio pipeline with Doc2Vec\n",
    "pipe_D2V_Rocchio = Pipeline(\n",
    "    [\n",
    "        ('reduce_dim', 'passthrough'),\n",
    "        ('clf', NearestCentroid())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tuning\n",
    "\n",
    "#Token \n",
    "min_DF = [1, 3, 10]\n",
    "max_DF = [0.6, 0.8, 0.9]\n",
    "#norm = ['l1','l2']\n",
    "\n",
    "#Dimensionality Reduction\n",
    "n_components = [115]\n",
    "\n",
    "#Classifer \n",
    "metric = ['euclidean', 'cosine']\n",
    "#shrink_threshold (for sinking centroids to remove fatures)\n",
    "\n",
    "#Parameter dictionary for Rocchio Pipeline\n",
    "Rocchio_params =[\n",
    "    {\n",
    "        'token_value': [CountVectorizer(), TfidfVectorizer()],\n",
    "        'token_value__min_df': min_DF,\n",
    "        'token_value__max_df': max_DF,\n",
    "        'reduce_dim': ['passthrough'],\n",
    "        'clf__metric': metric\n",
    "    },\n",
    "    {\n",
    "        'token_value': [CountVectorizer(), TfidfVectorizer()],\n",
    "        'token_value__min_df': min_DF,\n",
    "        'token_value__max_df': max_DF,\n",
    "        'reduce_dim': [TruncatedSVD()],\n",
    "        'reduce_dim__n_components': n_components,\n",
    "        'clf__metric': metric\n",
    "    }\n",
    "]\n",
    "\n",
    "#Doc2Vec parameter dictionary for Rocchio pipeline\n",
    "D2V_Rocchio_params =[\n",
    "    {\n",
    "        'reduce_dim': ['passthrough'],\n",
    "        'clf__metric': metric\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [TruncatedSVD()],\n",
    "        'reduce_dim__n_components': n_components,\n",
    "        'clf__metric': metric\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline with parameter dictionary\n",
    "pipe_param_dict['Rocchio_pipeline'] = [pipe_Rocchio, Rocchio_params]\n",
    "pipe_param_dict['Doc2Vec_Rocchio_pipeline']= [pipe_D2V_Rocchio, D2V_Rocchio_params]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune Rocchio model without Doc2Vec via GridSearchCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rocchio_best = run_on_subset(pipe_param_dict['Rocchio_pipeline'], subsets['balanced'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explanation of best parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune Rocchio model with Doc2Vec via GridSearchCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc2Vec_Rocchio_best = run_on_subset(pipe_param_dict['Doc2Vec_Rocchio_pipeline'], subsets['balanced_D2V'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explanation of best parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline using term counts and complimentary Naive Bayes\n",
    "pipe_CountVect_CompNB = Pipeline([\n",
    "    ('count', CountVectorizer()),\n",
    "    ('clf', ComplementNB())\n",
    "    ])\n",
    "\n",
    "# pipeline using Tfidf and complimentary Naive Bayes\n",
    "pipe_TfidfVect_CompNB = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    (\"clf\", ComplementNB())\n",
    "    ])\n",
    "\n",
    "# pipeline using Doc2Vec and complimentary Naive Bayes is incompatible as passes negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tunning\n",
    "\n",
    "# parameters for CountVectorizer()\n",
    "countvect_params = {\n",
    "    'count__min_df': [1, 3, 10], \n",
    "    'count__max_df': [0.6, 0.8, 0.9]\n",
    "    \n",
    "}\n",
    "\n",
    "# parameters for TfidfVectorizer()\n",
    "vectorizer_params = {\n",
    "    'vect__min_df': [1, 3, 10], \n",
    "    'vect__max_df': [0.6, 0.8, 0.9],\n",
    "    'vect__norm': ['l1','l2'],\n",
    "    'vect__binary': [False, True]\n",
    "}\n",
    "\n",
    "# parameters for Complimentary Naive Bayes()\n",
    "compNB_params = {\n",
    "    'clf__alpha' : [1, 10, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param_dict['CountVect_CompNB'] = [pipe_CountVect_CompNB, countvect_params]\n",
    "pipe_param_dict['TfidfVect_CompNB'] = [pipe_TfidfVect_CompNB, vectorizer_params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune Naive Bayes model with Term Frequencies via GridSearchCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_NB_best = run_on_subset(pipe_param_dict['CountVect_CompNB'], subsets['balanced'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explanation of best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune Naive Bayes model with TFIDF via GridSearchCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_NB_best = run_on_subset(pipe_param_dict['TfidfVect_CompNB'], subsets['balanced'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explanation of best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### KNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K Nearest Neighbors model depends on a distance or similarity function to compare how far apart instances (data points) are away from each other. In classification, for a given number of points, the majority label of these “nearest neighbors” to our point in question is assigned to our point. To tune our KNN model we examined three parameters. The first was the number of neighbors (k). A larger k should reduce the effects of noise but will make the classification boundary fuzzier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Pipeline\n",
    "pipe_KNN = Pipeline(\n",
    "    [\n",
    "        ('token_value', 'passthrough'),\n",
    "        ('reduce_dim', 'passthrough'),\n",
    "        ('clf', KNeighborsClassifier())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Doc2Vec KNN Pipeline\n",
    "pipe_D2V_KNN = Pipeline(\n",
    "    [\n",
    "        ('reduce_dim', 'passthrough'),\n",
    "        ('clf', KNeighborsClassifier())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tunning\n",
    "\n",
    "#Token parameters\n",
    "min_DF = [1, 3, 10]\n",
    "max_DF = [0.6, 0.8, 0.9]\n",
    "#norm = ['l1','l2']\n",
    "\n",
    "#Dimensionality Reduction parameters\n",
    "n_components = [115]\n",
    "\n",
    "#Classifer parameters\n",
    "n_neighbors = [5, 10]\n",
    "weights = ['uniform', 'distance']\n",
    "metric = ['minkowski', 'cosine']\n",
    "\n",
    "#Parameter dictionary for KNN Pipeline\n",
    "KNN_params =[\n",
    "    {\n",
    "        'token_value': [CountVectorizer(), TfidfVectorizer()],\n",
    "        'token_value__min_df': min_DF,\n",
    "        'token_value__max_df': max_DF,\n",
    "        'reduce_dim': ['passthrough'],\n",
    "        'clf__n_neighbors': n_neighbors,\n",
    "        'clf__weights': weights,\n",
    "        'clf__metric': metric\n",
    "    },\n",
    "    {\n",
    "        'token_value': [CountVectorizer(), TfidfVectorizer()],\n",
    "        'token_value__min_df': min_DF,\n",
    "        'token_value__max_df': max_DF,\n",
    "        'reduce_dim': [TruncatedSVD()],\n",
    "        'reduce_dim__n_components': n_components,\n",
    "        'clf__n_neighbors': n_neighbors,\n",
    "        'clf__weights': weights,\n",
    "        'clf__metric': metric\n",
    "    }\n",
    "]\n",
    "\n",
    "#Doc2Vec parameter dictionary for KNN pipeline\n",
    "D2V_KNN_params =[\n",
    "    {\n",
    "        'reduce_dim': ['passthrough'],\n",
    "        'clf__n_neighbors': n_neighbors\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [TruncatedSVD()],\n",
    "        'reduce_dim__n_components': n_components,\n",
    "        'clf__n_neighbors': n_neighbors\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline with parameter dictionary\n",
    "pipe_param_dict['KNN_pipeline'] = [pipe_KNN, KNN_params]\n",
    "pipe_param_dict['Doc2Vec_KNN_pipeline']= [pipe_D2V_KNN, D2V_KNN_params]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune KNN model without Doc2Vec via GridSearchCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_best = run_on_subset(pipe_param_dict['KNN_pipeline'], subsets['balanced'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explanation of best parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune KNN model with Doc2Vec via GridSearchCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc2Vec_KNN_best = run_on_subset(pipe_param_dict['Doc2Vec_KNN_pipeline'], subsets['balanced_D2V'])\n",
    "# function from Toxic_App_Tuning_&_Evaluation_funcs.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explanation of best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Evaluation of Models - Model Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradiant Descent/Logistic Regression (Xuyang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rocchio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_no_pred_prob(subsets['balanced'], target_names, Rocchio_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_no_pred_prob(subsets['balanced_D2V'], target_names, Doc2Vec_Rocchio_best)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis(subsets['balanced'], target_names, KNN_best, y_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis(subsets['balanced_D2V'], target_names, Doc2Vec_KNN_best, y_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis(subsets['balanced'], target_names, CV_NB_best, y_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis(subsets['balanced'], target_names, Tfidf_NB_best, y_score1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Model Evaluation Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(scores).set_index(\"Classifier/Pipeline\")\n",
    "score_df = score_df.round(2)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Top 3 Models with Unbalanced Dataset using Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimators = {\n",
    "    ('NaiveBayes', Tfidf_NB_best),\n",
    "    ('KNN', KNN_best),\n",
    "    ('Rocchio', Rocchio_best)\n",
    "}\n",
    "\n",
    "#create the ensemble classifier\n",
    "ensemble = VotingClassifier(estimators, voting = 'hard')\n",
    "\n",
    "#fit the model to the training data\n",
    "ensemble.fit(subsets['unbalanced'][0], subsets['unbalanced'][1])\n",
    "\n",
    "#test the model\n",
    "ensemble.score(subsets['unbalanced'][2], subsets['unbalanced'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_no_pred_prob(subsets['unbalanced'], target_names, ensemble)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

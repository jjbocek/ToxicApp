{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# A Toxic Comment Identifier Application - Main Notebook\n",
    "### DSC 478 - Winter 2023\n",
    "### Project Type: App Dev\n",
    "### Team Members: Jeff Bocek, Xuyang Ji, Anna-Lisa Vu\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "from itertools import cycle\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "#from sklearn's...\n",
    "from sklearn.feature_extraction.text import CountVectorizer #Convert a collection of text documents to a matrix of token counts.\n",
    "from sklearn.feature_extraction.text import TfidfTransformer #Transform a count matrix to a normalized tf or tf-idf representation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #Convert a collection of raw documents to a matrix of TF-IDF features\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,ParameterGrid #Cross validation gird search and training and testing chunks\n",
    "from sklearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.decomposition import TruncatedSVD,PCA #Dimension Reduction (LSA)\n",
    "from sklearn.preprocessing import Normalizer, LabelBinarizer \n",
    "from sklearn import preprocessing, model_selection, metrics\n",
    "from sklearn.ensemble import VotingClassifier #to create ensemble model\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import f1_score, mean_squared_error,accuracy_score,v_measure_score, silhouette_score,silhouette_samples\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import RocCurveDisplay, confusion_matrix, classification_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data Preprocessing & Exploratory Analysis \n",
    "\n",
    "[Exploratory_Data_cleaning.ipynb](Toxic_App_Exploratory_Data_Cleaning.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Cleaned and Processed Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading subset of training data with percentage of original instances:  \n",
    "1% of non-toxic comments: 1433  \n",
    "10% of toxic comments: 1370 and  \n",
    "100% of sever toxic comments: 1595\n",
    "\n",
    "Loading subset of testing data with percentage of original instances:  \n",
    "1% of non-toxic comments: 577  \n",
    "10% of toxic comments: 572 and   \n",
    "100% of sever toxic comments: 367"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_object = open('clean_data1.p', 'rb')\n",
    "clean_data = pickle.load(file_object)\n",
    "file_object.close()\n",
    "train = clean_data[0]\n",
    "test = clean_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balanced training data\n",
    "train_df_subset1 = train['comment_text']\n",
    "train_lab_subset1 = train['toxicity_level']\n",
    "\n",
    "#testing data\n",
    "test_df_subset1 = test['comment_text']\n",
    "test_lab_subset1 = test['toxicity_level']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading **uneven** subset of testing data with percentage of original instances:  \n",
    "1% of non-toxic comments: 577  \n",
    "20% of toxic comments: 1,144 and  \n",
    "100% of sever toxic comments: 367"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_object = open('clean_data_unbalanced.p', 'rb')\n",
    "clean_dataU = pickle.load(file_object)\n",
    "file_object.close()\n",
    "trainU = clean_dataU[0]\n",
    "testU = clean_dataU[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unbalanced training data\n",
    "train_df_subsetU = trainU['comment_text']\n",
    "train_lab_subsetU = trainU['toxicity_level']\n",
    "\n",
    "#testing data\n",
    "test_df_subsetU = testU['comment_text']\n",
    "test_lab_subsetU = testU['toxicity_level']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Term Frequencies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply put, the weights in the matrix represent the frequency of the term in a specific comment. The underlying concept is the higher the term frequency for a specific term in a comment, the more important it is for that comment. We use scikit-learn’s CountVectorizer(). Tuning occurred by adjusting the ‘max_df’ and ‘min_df’ which when building the vocabulary ignore terms that have a document frequency higher/lower respectively than the given threshold."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### TF*IDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Frequency - Inverse Document Frequency assesses how important a term is within a comment relative to our collection of comments. It does this by vectorizing and scoring a term by multiplying the term’s Term Frequency (TF; number of times the term appears in the comment over the total number of terms in the comment)  by the Inverse Document Frequency (IDF; the log of; the total number of comments over the total number of comments which contain the specific term plus one). By using this formula we don’t place added importance on the super common words which overshadow less common words which can show more meaning to the comments. We used scikit-learn’s TfidfVectorizer() to transform our preprocessed collection of comments into a TF-IDF matrix. In aberration to the basic formula referenced above TfidfVectorizer() adds a “+1” to the numerator and denominator of the IDF score to prevent zero divisions when the term is not present to better represent the IDF scores for sparse matrices. We tuned this transformation by trying two methods of normalization; ‘l1’ and ‘l2’. ‘l1’  normalized by using the sum of the absolute values of the vector elements is 1 while ‘l2’ is the Euclidean norm and the sum of squares of vector elements is 1. For ‘l2’ the cosine similarity between two vectors is their dot product. As was the case with Term Frequency tuning, tuned by adjusting the ‘max_df’ and ‘min_df’ which when building the vocabulary ignore terms that have a document frequency higher/lower respectively than the given threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF_func(data):\n",
    "    vectorizer= TfidfVectorizer(smooth_idf=True, sublinear_tf=False, norm=None, \n",
    "                         analyzer='word')\n",
    "    txt_fitted= vectorizer.fit(data)\n",
    "    txt_tranformed = txt_fitted.transform(data) \n",
    "    X_tfidf= txt_tranformed.toarray()\n",
    "    terms= txt_fitted.get_feature_names_out()\n",
    "    return X_tfidf, terms\n",
    "\n",
    "trainX_tfidf, terms_train= TFIDF_func(train_df_subset1)\n",
    "testX_tfidf, terms_test= TFIDF_func(test_df_subset1)\n",
    "trainXU_tfidf, termsU_train= TFIDF_func(train_df_subsetU)\n",
    "testXU_tfidf, termsU_test= TFIDF_func(test_df_subsetU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Doc2Vec\n",
    "Doc2Vec is a natural language processing technique to transform a set of documents into a list of vectors.  It is closely related to Word2Vec and is considered a more generalized form of it.  In Word2Vec, the algorithm looks at the context of each word and surrounding words. It assigns a numerical value to the word which represents the meaning of the word given its context.  For example, the chances of “Paris” and “France” being in the same sentence are higher than “Paris” and “power”.  Word2Vec takes this into consideration when creating the numerical value for each word. This example was taken from this [article](https://medium.com/wisio/a-gentle-introduction-to-doc2vec-db3e8c0cce5e).\n",
    "\n",
    "Doc2Vec has generalized this technique.  Instead of having a numeric representation for the words, you can achieve a numeric representation for a document as a whole.  We thought it would be a good exercise to use this data transformation technique in our project.  Each comment can be like a document.  To create the Doc2Vec vectors, we used the doc2Vec library package from the gensim.models library.  We ran this against the train and test data and fed that into our models.\n",
    "\n",
    "\n",
    "In the notebook below (which is in the same folder) are central methods we created so that we can get a doc2vec vector for the train and test data.  Using these methods each team member was able to feed a doc2vec transformed data set into the models.  Analysis and evaluations of our the models performed with the data set is explained in the upcoming sections.\n",
    "\n",
    "[Doc2Vec Notebook](Toxic_App_Doc2Vec.ipynb)\n",
    "(If the link doesn't work, please navigate to Toxic_App_Doc2Vec.ipynb in the same folder as this notebook)\n",
    "\n",
    "We ran the notebook in order to use common methods to infer doc2vec vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import doc2vec\n",
    "%run Toxic_App_Doc2Vec.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Infer vectors for a balanced data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced training set\n",
    "# Final set of parameters to use: 'dm': 0, 'vector_size': 1000, 'window': 5, 'hs': 1, 'negative': 0\n",
    "d2v_model = doc2vec.Doc2Vec(dm = 1, vector_size = 1000, window=5, min_count = 1, hs=1, epochs = 10)\n",
    "train_vectors1 = get_doc2vec_vectors(d2v_model, train_df_subset1)\n",
    "tokenized_test_comments = tokenize_comments(test_df_subset1)\n",
    "test_vectors1 = infer_vectors(d2v_model, tokenized_test_comments, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Infer vectors for an unbalanced data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unbalanced training set\n",
    "#Final set of parameters to use: 'dm': 0, 'vector_size': 1000, 'window': 5, 'hs': 1, 'negative': 0\n",
    "d2v_model = doc2vec.Doc2Vec(dm = 1, vector_size = 1000, window = 5, min_count = 1, hs=1, epochs = 10)\n",
    "train_vectorsU = get_doc2vec_vectors(d2v_model, train_df_subsetU)\n",
    "tokenized_test_comments = tokenize_comments(test_df_subsetU)\n",
    "test_vectorsU = infer_vectors(d2v_model, tokenized_test_comments, \"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary for Models\n",
    "Finally, we store the data sets from our transformations so that we can access them during model creation and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = {\n",
    "    # [X_train, y_train, X_test, y_test]\n",
    "    'balanced': [train_df_subset1, train_lab_subset1, test_df_subset1, test_lab_subset1],\n",
    "        # balanced training data with ratios 0.01, 0.10, 1.0\n",
    "    'balanced_TDIDF': [trainX_tfidf, terms_train, train_lab_subset1, testX_tfidf, terms_test, test_lab_subset1],\n",
    "    'balanced_D2V': [train_vectors1, train_lab_subset1, test_vectors1, test_lab_subset1],\n",
    "   \n",
    "    'unbalanced': [train_df_subsetU, train_lab_subsetU, test_df_subsetU, test_lab_subsetU],\n",
    "        # unbalanced training data with ratios 0.01, 0.20, 1.0\n",
    "    'unbalanced_TFIDF':[trainXU_tfidf, termsU_train,train_lab_subsetU, testXU_tfidf, termsU_test, test_lab_subsetU],\n",
    "    'unbalanced_D2V': [train_vectorsU, train_lab_subsetU, test_vectorsU, test_lab_subsetU],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSA for Dimension Reduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSA and Plot for Cumulative_explained_variance vs n_componenets\n",
    "def LSA(X, list_comp): \n",
    "    EVar=[] \n",
    "    for n_comp in list_comp:\n",
    "        lsa= make_pipeline(TruncatedSVD(n_components=n_comp), \n",
    "                           Normalizer(copy=False))\n",
    "        lsa.fit(X)\n",
    "        explainedVar = lsa[0].explained_variance_ratio_.sum()\n",
    "        EVar.append(explainedVar)\n",
    "        print(\"Number of components = %r and explained variance = %r\"%(n_comp,explainedVar))\n",
    "    plt.plot(list_comp,EVar, linewidth=2)\n",
    "    plt.xlabel('n_components')\n",
    "    plt.ylabel('Cumulative Explained Variance')\n",
    "    plt.title(\"Cumulative Explained Variance VS N_components\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components = 118 and explained variance = 0.9868905099708728\n",
      "Number of components = 108 and explained variance = 0.9847085007025582\n",
      "Number of components = 98 and explained variance = 0.9801368353365737\n",
      "Number of components = 88 and explained variance = 0.9717032026270795\n",
      "Number of components = 78 and explained variance = 0.957110773289083\n",
      "Number of components = 68 and explained variance = 0.9379413089116634\n",
      "Number of components = 58 and explained variance = 0.9091701214164302\n",
      "Number of components = 48 and explained variance = 0.868547136318125\n",
      "Number of components = 38 and explained variance = 0.7967933263973749\n",
      "Number of components = 28 and explained variance = 0.6993844493164424\n",
      "Number of components = 18 and explained variance = 0.5680000084131035\n",
      "Number of components = 8 and explained variance = 0.36021697671992625\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "step=10\n",
    "column= trainX_tfidf.shape[1] \n",
    "LSA(trainX_tfidf,range(column-(1470*step),0,-step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Supervised Modeling & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tuning and model evaluation functions\n",
    "%run Toxic_App_Tuning_&_Evaluation_funcs.ipynb\n",
    "pipe_param_dict = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression as the Benchmark\n",
    "\n",
    "The baseline model is a Logistic Regression model fit to tf-idf vectorized comment text with using only words for tokens, with the target value being toxicity_level. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_component= 116 with explained variance = 0.9857121388140746,the best parameters are: {'l1_ratio': 0.0, 'loss': 'log', 'n_jobs': -1, 'penalty': 'l2'}\n",
      "For n_component= 115 with explained variance = 0.9856165853541584,the best parameters are: {'l1_ratio': 0.9, 'loss': 'log', 'n_jobs': -1, 'penalty': 'elasticnet'}\n",
      "For n_component= 114 with explained variance = 0.9855221256726474,the best parameters are: {'l1_ratio': 0.0, 'loss': 'log', 'n_jobs': -1, 'penalty': 'l2'}\n",
      "For n_component= 113 with explained variance = 0.9854275219366397,the best parameters are: {'l1_ratio': 0.9, 'loss': 'log', 'n_jobs': -1, 'penalty': 'elasticnet'}\n",
      "For n_component= 112 with explained variance = 0.9853290749026669,the best parameters are: {'l1_ratio': 0.9, 'loss': 'log', 'n_jobs': -1, 'penalty': 'elasticnet'}\n",
      "For n_component= 111 with explained variance = 0.9852279677193385,the best parameters are: {'l1_ratio': 0.9, 'loss': 'log', 'n_jobs': -1, 'penalty': 'elasticnet'}\n"
     ]
    }
   ],
   "source": [
    "### Gradiant Descent/Logistic Regression as the Baseline Model \n",
    "skf= StratifiedKFold(n_splits=5,shuffle=True,random_state=961)\n",
    "target= np.array(train_lab_subset1)\n",
    "w=[]\n",
    "#loop through the value for svd dimension parameter\n",
    "for n in range(116,106,-1): #negative step to let range decrease from start\n",
    "    log=[]\n",
    "    for train_index, test_index in skf.split(trainX_tfidf,target):\n",
    "        xTrain, xTest= trainX_tfidf[train_index,:],trainX_tfidf[test_index,:]\n",
    "        yTrain,yTest= target[train_index],target[test_index]\n",
    "        lsa= make_pipeline(TruncatedSVD(n_components=n), Normalizer(copy=False))\n",
    "        xTrain_lsa= lsa.fit_transform(xTrain)\n",
    "        xTest_lsa= lsa.transform(xTest)    \n",
    "        explainedVar = lsa[0].explained_variance_ratio_.sum()\n",
    "        sdg_params = { \n",
    "            'loss': ['log'], \n",
    "            'penalty': ['l2','elasticnet'],\n",
    "            \"l1_ratio\" : np.arange(0,1,0.1),\n",
    "            'n_jobs': [-1]\n",
    "            }\n",
    "        model= SGDClassifier(max_iter= 3000,random_state=961)\n",
    "        grid= GridSearchCV(model, param_grid=sdg_params,cv=5)\n",
    "        grid.fit(xTrain_lsa,yTrain)\n",
    "        #model= LogisticRegression(solver='lbfgs',multi_class=\"multinomial\").fit(xTrain_lsa,yTrain)\n",
    "\n",
    "        BModel= SGDClassifier(**grid.best_params_, max_iter= 3000,random_state=961)\n",
    "        BModel.fit(xTrain_lsa,yTrain)\n",
    "\n",
    "        f1Train= f1_score(yTrain,BModel.predict(xTrain_lsa),average='weighted')\n",
    "        f1Test= f1_score(yTest,BModel.predict(xTest_lsa),average='weighted') \n",
    "        AccTest= accuracy_score(yTest,BModel.predict(xTest_lsa))\n",
    "        log.append([f1Train,f1Test,AccTest])\n",
    "    print(\"For n_component= %r with explained variance = %r,the best parameters are: %r\"%(n, explainedVar,grid.best_params_))\n",
    "    \n",
    "    mean= np.mean(log,axis=0)\n",
    "    F1_train= mean[0]\n",
    "    F1_test= mean[1]\n",
    "    Accu_Test= mean[2]\n",
    "\n",
    "    w.append([n,F1_train, F1_test, Accu_Test])  \n",
    "svd_dm= pd.DataFrame(w,columns=['N',\"F1_Train\",\"F1_Test\",\"Accuracy _Test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict (linestyle='dashed', linewidth=1.2,marker='o',\n",
    "               markerfacecolor='blue', markersize=3)\n",
    "line_plot= svd_dm.plot(x=\"N\",figsize=(7,3),**kwargs)\n",
    "line_plot.set_title('LSA Dimension Parameter v/s SGD Logistic Regression')\n",
    "line_plot.grid()\n",
    "line_plot.set_xlabel('N_components')\n",
    "line_plot.set_ylabel('F1_score/Accuracy')\n",
    "plt.show()\n",
    "bestN= svd_dm[svd_dm.index==svd_dm['F1_Test'].argmax()]\n",
    "bestN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Model to ensure data quality - K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### KMean\n",
    "lsa= make_pipeline(TruncatedSVD(n_components=109), Normalizer(copy=False))\n",
    "XLSA= lsa.fit_transform(trainX_tfidf)\n",
    "log = [] \n",
    "k_range = range(2,8) # Range of k values\n",
    "\n",
    "for k in k_range:\n",
    "    kmean = KMeans(n_clusters = k, random_state=961)\n",
    "    clusterLabel = kmean.fit_predict(XLSA)\n",
    "    inertia= kmean.inertia_\n",
    "    centroids= kmean.cluster_centers_\n",
    "    if True: # Generate Silhoettes Score\n",
    "        silhoettes_avg = silhouette_score(XLSA, clusterLabel)\n",
    "        log.append([k, inertia, silhoettes_avg])\n",
    "        continue\n",
    "    log.append([k, inertia])\n",
    "\n",
    "plot_df = pd.DataFrame(\n",
    "    log, columns = [\n",
    "        'k', 'Inertias (Sum of squared distances to Nearest Cluster Centroids)', 'Silhouette Coefficient'\n",
    "        ]\n",
    "    )\n",
    "fig, axes = plt.subplots(1,2, figsize=(18,7))\n",
    "sns.lineplot(\n",
    "    x='k', y='Inertias (Sum of squared distances to Nearest Cluster Centroids)', \n",
    "    data = plot_df, marker= 'o', ax = axes[0])\n",
    "axes[0].set_title(\"Elbow Method (Inertia)\")\n",
    "sns.lineplot(x='k', y='Silhouette Coefficient', data=plot_df, marker='o', ax = axes[1])\n",
    "axes[1].set_title(\"Silhoettes Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette_analysis_with_tsvd(n_clusters,X):\n",
    "    \n",
    "    # K-Mean Clustering\n",
    "    kmean = KMeans(n_clusters = n_clusters, random_state=961)\n",
    "    clusterLabel = kmean.fit_predict(X)\n",
    "    centroids= kmean.cluster_centers_\n",
    "\n",
    "    # Compute Individual Silhoette Score\n",
    "    silhoettes_avg = silhouette_score(X, clusterLabel)\n",
    "\n",
    "    # Compute Average Silhoette Score\n",
    "    sample_silhouette_values = silhouette_samples(X, clusterLabel)\n",
    "     # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    ################################### Silhouette Plot #############################################\n",
    " \n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    y_lower = 10\n",
    "\n",
    "    # Assign colours for different cluster\n",
    "    for i in range(n_clusters):\n",
    "         # Aggregate the silhouette scores for samples belonging to\n",
    "         # cluster i, and sort them\n",
    "         ith_cluster_silhouette_values = sample_silhouette_values[clusterLabel == i]\n",
    "         ith_cluster_silhouette_values.sort()\n",
    "         size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "         y_upper = y_lower + size_cluster_i\n",
    "         color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "         ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                           0, ith_cluster_silhouette_values,\n",
    "                           facecolor=color, edgecolor=color, alpha=0.7)\n",
    "         \n",
    "         ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "         y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"Silhouette Plot for Clusters.\")\n",
    "    ax1.set_xlabel(\"Silhouette Coefficient Values\")\n",
    "    ax1.set_ylabel(\"Cluster Label\")\n",
    "    # avg sil score \n",
    "    ax1.axvline(x=silhoettes_avg, color=\"red\", linestyle=\"--\")\n",
    "    ax1.set_yticks([]) \n",
    "    ax1.set_xticks([-0.2, 0, 0.2, 0.4, 0.6, 0.8])\n",
    "\n",
    "    ################################### SVD Plot #############################################\n",
    " \n",
    "    # Compute tsvd with only First 2 Number of Component\n",
    "    tsvd2 = TruncatedSVD(n_components=2)\n",
    "    sample2 = tsvd2.fit_transform(X)\n",
    "\n",
    "    ##Getting diff color for diff cluster \n",
    "    colors = cm.nipy_spectral(clusterLabel.astype(float) / n_clusters)\n",
    "    ax2.scatter(sample2[:,0], sample2[:,1], marker='.', s=70, lw=0, alpha=1,\n",
    "            c=colors, edgecolor='k')\n",
    "\n",
    "    centers = centroids.dot(tsvd2.components_.T) # Cluster Positions after transformation \n",
    "    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                 c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "                    s=50, edgecolor='k')\n",
    "    ax2.set_title(\"The visualization of TSVD with total explained variance of {:.2f}%.\".format(tsvd2.explained_variance_ratio_.sum()*100))\n",
    "    ax2.set_xlabel(\"Feature space for the 1st component\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd component\")\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on Toxic Comment Dataset\"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, k in enumerate(range(3,5)): # Analyse k = (3,4)\n",
    "    silhouette_analysis_with_tsvd(n_clusters = k, X = XLSA)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go with k=3\n",
    "kmean3 = KMeans(n_clusters = 3, random_state=961)\n",
    "clusterLabel3 = kmean3.fit_predict(XLSA)\n",
    "centroids3= kmean3.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_space_centroids = lsa[0].inverse_transform(kmean3.cluster_centers_)\n",
    "order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "labels = train.toxicity_level\n",
    "unique_labels, category_sizes = np.unique(labels, return_counts=True)\n",
    "true_k = unique_labels.shape[0]\n",
    "\n",
    "for i in range(true_k):\n",
    "    print(f\"Cluster {i}: \", end=\"\")\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(f\"{terms_train[ind]} \", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confuM= confusion_matrix(labels,kmean3.labels_)\n",
    "sns.set()\n",
    "ax=sns.heatmap(confuM,annot=True,fmt=\"d\",cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Pipeline\n",
    "\n",
    "LSA109= make_pipeline(TruncatedSVD(n_components=109), Normalizer(copy=False))\n",
    "\n",
    "pipe_logistic = Pipeline(\n",
    "    [\n",
    "        ('token_value', 'passthrough'),\n",
    "        ('reduce_dim', 'passthrough'),\n",
    "        ('clf', SGDClassifier(max_iter= 8000,random_state=961))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Logistic pipeline with Doc2Vec\n",
    "pipe_D2V_logistic = Pipeline(\n",
    "    [\n",
    "        ('reduce_dim', 'passthrough'),\n",
    "        ('clf', SGDClassifier(max_iter= 8000,random_state=961))\n",
    "    ]\n",
    ")\n",
    "\n",
    "Logistic_params =[\n",
    "    {\n",
    "        'token_value': [CountVectorizer(), TfidfVectorizer()],\n",
    "        'token_value__min_df': [1, 3, 10],\n",
    "        'token_value__max_df': [0.6,0.8,0.9],\n",
    "        'reduce_dim': [Normalizer(copy=False)],\n",
    "        'clf__loss': ['log'],\n",
    "        'clf__penalty':['elasticnet'],\n",
    "        'clf__l1_ratio': [0.9],\n",
    "        'clf__n_jobs':[-1]\n",
    "    },\n",
    "            \n",
    "    {\n",
    "        'token_value': [CountVectorizer(), TfidfVectorizer()],\n",
    "        'token_value__min_df': [1,3,10,],\n",
    "        'token_value__max_df': [0.6,0.8,0.9],\n",
    "        'reduce_dim': [LSA109],\n",
    "        'clf__loss': ['log'],\n",
    "        'clf__penalty':['elasticnet'],\n",
    "        'clf__l1_ratio': [0.9],\n",
    "        'clf__n_jobs':[-1]\n",
    "    }\n",
    "]\n",
    "#Doc2Vec parameter dictionary for Logistic pipeline\n",
    "D2V_logistic_params =[\n",
    "    {\n",
    "        'reduce_dim': ['passthrough'],\n",
    "        'clf__loss': ['log'],\n",
    "        'clf__penalty':['elasticnet'],\n",
    "        'clf__l1_ratio': [0.9],\n",
    "        'clf__n_jobs':[-1]\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [LSA109],\n",
    "        'clf__loss': ['log'],\n",
    "        'clf__penalty':['elasticnet'],\n",
    "        'clf__l1_ratio': [0.9],\n",
    "        'clf__n_jobs':[-1]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline with parameter dictionary\n",
    "pipe_param_dict['Logistic_pipeline'] = [pipe_logistic, Logistic_params]\n",
    "pipe_param_dict['Doc2Vec_logistic_pipeline']= [pipe_D2V_logistic, D2V_logistic_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_best= run_on_subset(pipe_param_dict['Logistic_pipeline'],subsets['balanced'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc2Vec_logstic_best = run_on_subset(pipe_param_dict['Doc2Vec_logistic_pipeline'], subsets['balanced_D2V'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Nearest Centroid\n",
    "\n",
    "In the Nearest Centroid classifier, a mean centroid is calculated from the training set for each class. The model uses the label of the closest centroid to the test instance to classify the test instance.\n",
    "\n",
    "Below, we use the NearestCentroid implementation from the sklean library for this model.  There are 2 different pipelines, one that uses a CountVectorizer (term counts) and a TFIDVectorizer (TF*IDF) as well as one that will use a Doc2Vec vector for data transformation.  These pipelines are passed into a shared method where we are running all our pipelines.  The best parameters are printed after running the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rocchio Pipeline\n",
    "pipe_Rocchio = Pipeline(\n",
    "    [\n",
    "        ('token_value', 'passthrough'),\n",
    "        ('reduce_dim', 'passthrough'),\n",
    "        ('clf', NearestCentroid())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Rocchio pipeline with Doc2Vec\n",
    "pipe_D2V_Rocchio = Pipeline(\n",
    "    [\n",
    "        ('reduce_dim', 'passthrough'),\n",
    "        ('clf', NearestCentroid())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For hyperparameter tuning, I had to split out the tuning of the full feature set vs. the truncated feature set (via SVD).  This was so that my pipelines could finish in a reasonable time.  I attempted to try tuning with the shrink_threshold parameter which is included with the Nearest Centroid classifier; however, I kept getting an error stating \"threshold shrinking not supported for sparse input\".  Therefore, I had to leave that out for tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tuning\n",
    "\n",
    "#Token \n",
    "min_DF = [1, 3, 10]\n",
    "max_DF = [0.6, 0.8, 0.9]\n",
    "#norm = ['l1','l2']\n",
    "\n",
    "#Dimensionality Reduction\n",
    "#LSA109= make_pipeline(TruncatedSVD(n_components=109), Normalizer(copy=False))\n",
    "\n",
    "#Classifer \n",
    "metric = ['euclidean', 'cosine']\n",
    "#shrink_threshold = ['None', 0.2]\n",
    "\n",
    "#Parameter dictionary for Rocchio Pipeline\n",
    "Rocchio_params =[\n",
    "    {\n",
    "        'token_value': [CountVectorizer(), TfidfVectorizer()],\n",
    "        'token_value__min_df': min_DF,\n",
    "        'token_value__max_df': max_DF,\n",
    "        'reduce_dim': ['passthrough'],\n",
    "        'clf__metric': metric\n",
    "    }\n",
    "]\n",
    "\n",
    "Rocchio_params_svd =[\n",
    "    {\n",
    "        'token_value': [CountVectorizer(), TfidfVectorizer()],\n",
    "        'token_value__min_df': min_DF,\n",
    "        'token_value__max_df': max_DF,\n",
    "        'reduce_dim': [LSA109],\n",
    "        'clf__metric': metric\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "#Doc2Vec parameter dictionary for Rocchio pipeline\n",
    "#We will pass in the data directly instead of going through a\n",
    "#CountVectorizer or TfidVectorizer\n",
    "D2V_Rocchio_params =[\n",
    "    {\n",
    "        'reduce_dim': ['passthrough'],\n",
    "        'clf__metric': metric,\n",
    "    },\n",
    "     {\n",
    "        'reduce_dim': [LSA109],\n",
    "        'clf__metric': metric\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Below we create the dictionaries to pass into our custom run and evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline with parameter dictionary\n",
    "pipe_param_dict['Rocchio_pipeline'] = [pipe_Rocchio, Rocchio_params]\n",
    "pipe_param_dict['Rocchio_pipeline_svd'] = [pipe_Rocchio, Rocchio_params_svd]\n",
    "pipe_param_dict['Doc2Vec_Rocchio_pipeline']= [pipe_D2V_Rocchio, D2V_Rocchio_params]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune Nearest Centroid model using Count and Term Vectorizer via GridSearchCV() for a Balanced Data Set\n",
    "(Note there are user warnings being thrown since we are passing in a cosine distance metric when evaluate the NearestCentroid.These can be ignored for now.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocchio_best = run_on_subset(pipe_param_dict['Rocchio_pipeline'], subsets['balanced'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rocchio_best_svd = run_on_subset(pipe_param_dict['Rocchio_pipeline_svd'], subsets['balanced'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Based on the above, our method found that the best parameters for the Nearest Centroid model for both a full and truncated balanced data set are the following:\n",
    "    * metric: cosine\n",
    "    * data transformation: TfidfVectorizer using a max of 0.6 and a min of 1 (Note: when using float in these values, it is taken as a proportion instead of the value itself)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune Nearest Centroid model with Doc2Vec via GridSearchCV() for a Balanced Data Set\n",
    "(Note there are user warnings being thrown since we are passing in a cosine distance metric when evaluate the NearestCentroid.These can be ignored for now.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2Vec_rocchio_best = run_on_subset(pipe_param_dict['Doc2Vec_Rocchio_pipeline'], subsets['balanced_D2V'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Based on the above, our method found that the best parameters for the Nearest Centroid model for both a full and truncated Doc2Vec data set are the following:\n",
    "    * metric: cosine\n",
    "    * data transformation: Doc2Vec\n",
    "    * reduction: passthrough (non-svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For all our evaluations, the settings below were chosen as the best.  Therefore, when we evaluate this model in the next section we will be using these parameters:\n",
    "    * metric: cosine\n",
    "    * For TfidfVectorizer using a max of 0.6 and a min of 1 (Note: when using float in these values, it is taken as a proportion instead of the value itself)\n",
    "    * For Doc2Vec, using a non-reduced data set\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes model uses the probabilities of the features and vectors to predict the class of our comments. The NB assumes independence between the features and a normal distribution. NB was chosen as it works well with text classification with a multiclass problem. We included the smoothing parameter in our tuning to account for small samples which use Laplace smoothing to correct for zero frequency issues. Truncated SVD (feature reduction) and using Doc2Vec were unable to be used as NB is incompatible with passing negative values. If we had more time we could have explored the correlations between the terms to try and reduce our features so we reduce the inflating of importance. While our dataset is not severely unbalanced we used Complement Naive Bayes (CNB) as it performs better on text classification than the standard Multinomial Naive Bayes. CNB uses the complement of each class to compute the model’s weights. It applies a second normalization to address the tendency for longer documents to dominate parameter estimates in MNB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline using term frequency and complimentary Naive Bayes\n",
    "pipe_CountVect_CompNB = Pipeline([\n",
    "    ('count', CountVectorizer()),\n",
    "    ('clf', ComplementNB())\n",
    "    ])\n",
    "\n",
    "# pipeline using Tfidf and complimentary Naive Bayes\n",
    "pipe_TfidfVect_CompNB = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    (\"clf\", ComplementNB())\n",
    "    ])\n",
    "\n",
    "# pipeline using Doc2Vec and complimentary Naive Bayes is incompatible as passes negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tunning\n",
    "\n",
    "# parameters for CountVectorizer() (see above Term Frequency)\n",
    "countvect_params = {\n",
    "    'count__min_df': [1, 3, 10], \n",
    "    'count__max_df': [0.6, 0.8, 0.9]\n",
    "    \n",
    "}\n",
    "\n",
    "# parameters for TfidfVectorizer() (see above Tfidf)\n",
    "vectorizer_params = {\n",
    "    'vect__min_df': [1, 3, 10], \n",
    "    'vect__max_df': [0.6, 0.8, 0.9],\n",
    "    'vect__norm': ['l1','l2']\n",
    "}\n",
    "\n",
    "# parameters for Complimentary Naive Bayes()\n",
    "compNB_params = {\n",
    "    'clf__alpha' : [0, 1]       #smoothing parameter to reduce zero frequency effects if alpha = 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_param_dict['CountVect_CompNB'] = [pipe_CountVect_CompNB, countvect_params]\n",
    "pipe_param_dict['TfidfVect_CompNB'] = [pipe_TfidfVect_CompNB, vectorizer_params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune Naive Bayes model with Term Frequencies via GridSearchCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_NB_best = run_on_subset(pipe_param_dict['CountVect_CompNB'], subsets['balanced'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explanation of best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune Naive Bayes model with TFIDF via GridSearchCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_NB_best = run_on_subset(pipe_param_dict['TfidfVect_CompNB'], subsets['balanced'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explanation of best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### KNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K Nearest Neighbors model depends on a distance or similarity function to compare how far apart instances (data points) are away from each other. In classification, for a given number of points, the majority label of these “nearest neighbors” is assigned to our point in question. To tune our KNN model we examined three parameters. The first was the number of neighbors (k). A larger k should reduce the effects of noise but will make the classification boundary fuzzier. A smaller k could overfit the model. The second parameter used was the type of distance function used to measure between the points. We tried either the cosine distance which measures the angle between the two vectors of the points and the minkowski distance with p= 2 which is the euclidian distance function (pythagorean distance). Typically when dealing with sparse data (text data) the cosine distance helps the model to perform better. The last parameter tuned was the weights function used in the prediction of points using the model. We examined uniform weights (all the neighbors are weighed the same) versus distance weights which the closer neighbors will have a stronger impact than the ones further away.  \n",
    "\n",
    "*Best tuned model*:  We used scikit-learn’s GridSearchCV() to search which of these parameters would produce the best model using stratified five-fold cross validation which preserves the percentage of samples for each class. Our best model used the Term Frequency vectors (not Tfidf) with a , no dimensionality reduction (vs, SVD), the cosine distance, ten nearest neighbors, and the neighbor weights were uniform. The model using Doc2Vec instead of Term Frequency had the same parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Pipeline\n",
    "pipe_KNN = Pipeline(\n",
    "    [\n",
    "        ('token_value', 'passthrough'),         #use Term Frequency or Tfidf\n",
    "        ('reduce_dim', 'passthrough'),          # use truncated SVD or none for dimension reduction\n",
    "        ('clf', KNeighborsClassifier())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Doc2Vec KNN Pipeline\n",
    "pipe_D2V_KNN = Pipeline(\n",
    "    [\n",
    "        ('reduce_dim', 'passthrough'),          # use truncated SVD or none for dimension reduction\n",
    "        ('clf', KNeighborsClassifier())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tunning\n",
    "\n",
    "#Token parameters (see Term Frequency above)\n",
    "min_DF = [1, 3, 10]\n",
    "max_DF = [0.6, 0.8, 0.9]\n",
    "\n",
    "#Dimensionality Reduction parameters\n",
    "#LSA109= make_pipeline(TruncatedSVD(n_components=109), Normalizer(copy=False))\n",
    "\n",
    "#Classifer parameters\n",
    "n_neighbors = [5, 10]\n",
    "weights = ['uniform', 'distance']\n",
    "metric = ['minkowski', 'cosine']\n",
    "\n",
    "#Parameter dictionary for KNN Pipeline\n",
    "KNN_params =[\n",
    "    {\n",
    "        'token_value': [CountVectorizer(), TfidfVectorizer()],\n",
    "        'token_value__min_df': min_DF,\n",
    "        'token_value__max_df': max_DF,\n",
    "        'reduce_dim': ['passthrough'],\n",
    "        'clf__n_neighbors': n_neighbors,\n",
    "        'clf__weights': weights,\n",
    "        'clf__metric': metric\n",
    "    },\n",
    "    {\n",
    "        'token_value': [CountVectorizer(), TfidfVectorizer()],\n",
    "        'token_value__min_df': min_DF,\n",
    "        'token_value__max_df': max_DF,\n",
    "        'reduce_dim': [LSA109],                                     \n",
    "        'clf__n_neighbors': n_neighbors,\n",
    "        'clf__weights': weights,\n",
    "        'clf__metric': metric\n",
    "    }\n",
    "]\n",
    "\n",
    "#Doc2Vec parameter dictionary for KNN pipeline\n",
    "D2V_KNN_params =[\n",
    "    {\n",
    "        'reduce_dim': ['passthrough'],\n",
    "        'clf__n_neighbors': n_neighbors\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [LSA109],\n",
    "        'clf__n_neighbors': n_neighbors\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline with parameter dictionary\n",
    "pipe_param_dict['KNN_pipeline'] = [pipe_KNN, KNN_params]\n",
    "pipe_param_dict['Doc2Vec_KNN_pipeline']= [pipe_D2V_KNN, D2V_KNN_params]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune KNN model without Doc2Vec via GridSearchCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_best = run_on_subset(pipe_param_dict['KNN_pipeline'], subsets['balanced'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explanation of best parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune KNN model with Doc2Vec via GridSearchCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc2Vec_KNN_best = run_on_subset(pipe_param_dict['Doc2Vec_KNN_pipeline'], subsets['balanced_D2V'])\n",
    "# function from Toxic_App_Tuning_&_Evaluation_funcs.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explanation of best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Evaluation of Models - Model Comparisons"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those models where appropriate we evaluated the confusion matrix, accuracy, and ROC AUC score for each model. As part of the confusion matrix evaluation we looked at the precision, recall, and F1 scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradiant Descent/Logistic Regression (Xuyang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_no_pred_prob(subsets['balanced'], target_names, Logistic_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_no_pred_prob(subsets['balanced_D2V'], target_names, Doc2Vec_logstic_best)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rocchio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_no_pred_prob(subsets['balanced'], target_names, rocchio_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_no_pred_prob(subsets['balanced_D2V'], target_names, doc2Vec_rocchio_best)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis(subsets['balanced'], target_names, KNN_best, y_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis(subsets['balanced_D2V'], target_names, Doc2Vec_KNN_best, y_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis(subsets['balanced'], target_names, CV_NB_best, y_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis(subsets['balanced'], target_names, Tfidf_NB_best, y_score1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Model Evaluation Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(scores).set_index(\"Classifier/Pipeline\")\n",
    "score_df = score_df.round(2)\n",
    "score_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In comparing our different tuned models we found the following three the best:  \n",
    "* Stochastic Gradient Descent Logistic Regression using the Tfidf matrix and normalized truncated Singular Value Decomposition.\n",
    "* Rocchio (Nearest Centroid) using the Tfidf matrix.\n",
    "* Compliment Naive Bayes  using the Tfidf matrix.  \n",
    "\n",
    "We made this determination primarily on the F1 score. The F1 score represents precision and recall in one metric. We are interested in classifying our comments as non-toxic, toxic, or severely toxic. Most importantly we want to minimize our False Negative rate. If a comment is toxic, we do not want to label it as non-toxic and thus not be flagged or removed by the application. Hence, we paid special attention to the recall score which focuses on the false negatives. Looking at the confusion matrices below, we see the most errors in trying to classify the toxic comments (label “1”). If we had to choose the best model, we would use Gradient Descent Logistic Regression because it has the lowest instances of classifying toxic and severely toxic comments as non toxic (5.8% and 0.26% respectively).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Tested on Unbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset scores dataframe\n",
    "scores = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compliment Naive Bayes with unbalanced test data\n",
    "analysis(subsets['unbalanced'], target_names, Tfidf_NB_best, y_score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Descent Logistic Regression with unbalanced test data\n",
    "analysis_no_pred_prob(subsets['unbalanced'], target_names, rocchio_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rocchio with unbalanced test data\n",
    "analysis_no_pred_prob(subsets['unbalanced'], target_names, Logistic_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(scores).set_index(\"Classifier/Pipeline\")\n",
    "score_df = score_df.round(2)\n",
    "score_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further evaluate the best three models we test the models using unbalanced test data. The original test data had instances of non-toxic (577), toxic (572), and severely toxic (367). For using unbalanced test data we doubled the toxic instances to 1,144. From the confusion the analysis results we see that the Complement Naive Bayes model improved performance on this test data. This may have occurred by giving increased instances to toxic so the model could differentiate them better. The toxic class is where all of our models struggled to predict. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Top 3 Models with Unbalanced Dataset using Ensemble"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an attempt to improve our models we created a simple ensemble model which combined these three best models by a “hard” vote, or a simple majority vote between the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimators = {\n",
    "    ('NaiveBayes', Tfidf_NB_best),\n",
    "    ('SGD_Logistic', Logistic_best),\n",
    "    ('Rocchio', rocchio_best)\n",
    "}\n",
    "\n",
    "#create the ensemble classifier\n",
    "ensemble = VotingClassifier(estimators, voting = 'hard')\n",
    "\n",
    "#fit the model to the training data\n",
    "#ensemble.fit(subsets['unbalanced'][0], subsets['unbalanced'][1])\n",
    "\n",
    "#test the model\n",
    "#ensemble.score(subsets['unbalanced'][2], subsets['unbalanced'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_no_pred_prob(subsets['unbalanced'], target_names, ensemble)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

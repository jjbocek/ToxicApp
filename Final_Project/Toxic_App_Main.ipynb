{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# A Toxic Comment Identifier Application - Main Notebook\n",
    "### DSC 478 - Winter 2023\n",
    "### Project Type: App Dev\n",
    "### Team Members: Jeff Bocek, Xuyang Ji, Anna-Lisa Vu\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exploratory Analysis (Xuyang)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#[Link to Toxic_App_Exploratory_Data_Cleaning]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-processing of Data (Xuyang)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#[Link to Toxic_App_Exploratory_Data_Cleaning]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Transformation (Lisa)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#[Link to Toxic_App_Transformation notebook (if needed)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Term Frequencies (Jeff)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TF*IDF (Jeff)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Doc2Vec (Lisa)\n",
    "Doc2Vec is a natural language processing technique to transform a set of documents into a list of vectors. It is closely related to the Word2Vec technique and is considered a more generalized form of it.  To best understand Doc2Vec, it is imperative to understad Word2Vec.  In Word2Vec, the algorithm looks at the context of each word and what other words surround it.  It assigns a numerical number to the word which represents the meaning of the word given its context.  For example. if Paris and France are in the same sentence, Word2Vec will create a number for each of these words which would represent that these 2 words are related.  This is exact same example is referenced in this article: https://medium.com/wisio/a-gentle-introduction-to-doc2vec-db3e8c0cce5e  Doc2Vec on the other hand generalized this technique.  Instead of having a numeric representation for the words, with Doc2Vec you can achieve a numeric representation for a document as a whole.\n",
    "\n",
    "We thought it would be a good exercise to use this data transformation technique in our project.  Each comment can be like a document.  To create the Doc2Vec vectors, we used the doc2Vec library package from the gensim.models library.  We ran this against the train and test data and feed that into our models.\n",
    "\n",
    "In the attached notebook are central methods we created so that we can get a doc2vec vector for the train and test data.  Using these methods each team member was able to feed a doc2vec transformed data set into the models.  Analysis and Evaluations of our the models performed with the data set is explained in the upcoming sections.\n",
    "\n",
    "Link to Doc2Vec Notebook: [Toxic_App_Doc2Vec.ipynb](Toxic_App_Doc2Vec.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Unsupervised Modeling for Exploratory Analysis\n",
    "### Kmeans (Xuyang)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Supervised Modeling & Hyperparameter Tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gradiant Descent/Logistic Regression (Xuyang)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Rocchio/Nearest Centroid (Lisa)\n",
    "\n",
    "Explanation goes here."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Naive Bayes (Jeff)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KNN (Jeff)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation of Models - Model Comparisons"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#[Dataframe of evaluation]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Top 3 Models with Unbalanced Dataset using Ensemble"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

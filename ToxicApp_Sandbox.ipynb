{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A sandbox to test code, post ideas, etc. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "#from sklearn's...\n",
    "from sklearn.feature_extraction.text import CountVectorizer #Convert a collection of text documents to a matrix of token counts.\n",
    "from sklearn.feature_extraction.text import TfidfTransformer #Transform a count matrix to a normalized tf or tf-idf representation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #Convert a collection of raw documents to a matrix of TF-IDF features\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We have three datasets we are using; training (**train_ds**), testing (**test_ds**), and testing labels (**test_labels_ds**)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load training and test dataframes from file; preprocessing completed in 'text_preprocessing' notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_object = open('clean_data.p', 'rb')\n",
    "clean_data = pickle.load(file_object)\n",
    "train_ds = clean_data[0]\n",
    "test_ds = clean_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explanation edit make username hardcore metall...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>daww match background colour im seemingly stic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man im really try edit war guy constantly ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  explanation edit make username hardcore metall...      0   \n",
       "1  000103f0d9cfb60f  daww match background colour im seemingly stic...      0   \n",
       "2  000113f07ec002fd  hey man im really try edit war guy constantly ...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>yo bitch ja rule succesful youll ever whats ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>rfc title fine imo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>source zawe ashton lapland —</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  yo bitch ja rule succesful youll ever whats ha...\n",
       "1  0000247867823ef7                                 rfc title fine imo\n",
       "2  00013b17ad220c46                       source zawe ashton lapland —"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels = pd.read_csv('test_labels.csv', header = 0)\n",
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0  00001cee341fdb12     -1            -1       -1      -1      -1   \n",
       "1  0000247867823ef7     -1            -1       -1      -1      -1   \n",
       "\n",
       "   identity_hate  \n",
       "0             -1  \n",
       "1             -1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsets of data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset1: Create a subsample of data for quickened runtime with only 'toxic' as labels(Subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset of testing data; removed the id column\n",
    "train_ds_subset = train_ds.loc[1:1000,'comment_text']\n",
    "train_labels_subset = train_ds.loc[1:1000,'toxic']\n",
    "\n",
    "#subset of testing data; removed the id column\n",
    "test_ds_subset = test_ds.loc[1:1000,'comment_text']\n",
    "test_labels_subset = test_labels.loc[1:1000,'toxic']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset2: Create a subsample of data with full training set and test set instances with -1's were dropped. Only used 'toxic' labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63978\n",
      "63978\n"
     ]
    }
   ],
   "source": [
    "#subset of testing data; removed the id column\n",
    "train_ds_subset2 = train_ds.loc[:,'comment_text']\n",
    "train_labels_subset2 = train_ds.loc[:,'toxic']\n",
    "\n",
    "#remove -1s\n",
    "non_null_data = test_labels[test_labels.loc[:,'toxic'] != -1]\n",
    "#subset of testing data; removed the id column\n",
    "test_ds_subset2 =test_ds.loc[non_null_data.index]\n",
    "test_ds_subset2 = test_ds_subset2.loc[:,'comment_text']\n",
    "test_labels_subset2 = non_null_data.loc[:,'toxic']\n",
    "print(test_ds_subset2.size)\n",
    "print(test_labels_subset2.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explanation edit make username hardcore metall...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>daww match background colour im seemingly stic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  explanation edit make username hardcore metall...      0   \n",
       "1  000103f0d9cfb60f  daww match background colour im seemingly stic...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 1, 3, 2, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.loc[:,'toxic':'identity_hate'].sum(axis =1).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Could convert the comment labels to one label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>001810bf8c45bf5f</td>\n",
       "      <td>gay antisemmitian archangel white tiger meow g...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>00472b8e2d38d1ea</td>\n",
       "      <td>pair jewhating weiner nazi schmuck</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>006b94add72ed61c</td>\n",
       "      <td>think fagget get oife burn hell hate sorry can...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>008e0818dde894fb</td>\n",
       "      <td>kill nigger hard others say include racist som...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0097dd5c29bf7a15</td>\n",
       "      <td>u r tw fuck u gay boyu r smellyfuck ur mum poopie</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159281</th>\n",
       "      <td>fb726deec64157bd</td>\n",
       "      <td>lol youre gay never know good feel fuck woman as</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159336</th>\n",
       "      <td>fc3efa2f6f025f6d</td>\n",
       "      <td>oh fuck pansy jew would whine bnai brith beat ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159400</th>\n",
       "      <td>fd052883fa6a8697</td>\n",
       "      <td>shalom semite get fuck kill son bitch dont lea...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>fdce660ddcd6d7ca</td>\n",
       "      <td>think gay fag</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159494</th>\n",
       "      <td>fef4cf7ba0012866</td>\n",
       "      <td>previous conversation fuck shit eat liberal ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1302 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "42      001810bf8c45bf5f  gay antisemmitian archangel white tiger meow g...   \n",
       "105     00472b8e2d38d1ea                 pair jewhating weiner nazi schmuck   \n",
       "176     006b94add72ed61c  think fagget get oife burn hell hate sorry can...   \n",
       "218     008e0818dde894fb  kill nigger hard others say include racist som...   \n",
       "238     0097dd5c29bf7a15  u r tw fuck u gay boyu r smellyfuck ur mum poopie   \n",
       "...                  ...                                                ...   \n",
       "159281  fb726deec64157bd   lol youre gay never know good feel fuck woman as   \n",
       "159336  fc3efa2f6f025f6d  oh fuck pansy jew would whine bnai brith beat ...   \n",
       "159400  fd052883fa6a8697  shalom semite get fuck kill son bitch dont lea...   \n",
       "159449  fdce660ddcd6d7ca                                      think gay fag   \n",
       "159494  fef4cf7ba0012866  previous conversation fuck shit eat liberal ma...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "42          1             0        1       0       1              1  \n",
       "105         1             0        1       0       1              1  \n",
       "176         1             0        1       1       1              1  \n",
       "218         1             0        1       0       1              1  \n",
       "238         1             0        1       0       1              1  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "159281      1             1        1       0       1              1  \n",
       "159336      1             0        1       0       1              1  \n",
       "159400      1             1        1       1       1              1  \n",
       "159449      1             0        0       0       0              1  \n",
       "159494      1             0        1       0       1              1  \n",
       "\n",
       "[1302 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[(train_ds['toxic'] == 1) & (train_ds['identity_hate'] == 1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample how we did it in homework just on 5 comments as corpus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get term count matrix along with terms array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['accident', 'actual', 'appear', 'article', 'background', 'backlog',\n",
       "       'cant', 'care', 'chance', 'closure', 'colour', 'constantly',\n",
       "       'date', 'daww', 'delay', 'doll', 'dont', 'edit', 'eg', 'else',\n",
       "       'etc', 'exact', 'explanation', 'fac', 'fan', 'first', 'form',\n",
       "       'format', 'gas', 'guess', 'guy', 'hardcore', 'hero', 'hey', 'ie',\n",
       "       'im', 'improvement', 'info', 'information', 'instead', 'january',\n",
       "       'know', 'later', 'let', 'list', 'make', 'man', 'match', 'may',\n",
       "       'metallica', 'need', 'new', 'noone', 'page', 'please',\n",
       "       'preference', 'real', 'really', 'reference', 'relevant',\n",
       "       'remember', 'remove', 'retire', 'revert', 'review', 'reviewer',\n",
       "       'section', 'seem', 'seemingly', 'since', 'sir', 'statistic',\n",
       "       'stick', 'style', 'subsection', 'suggestion', 'talk', 'template',\n",
       "       'thank', 'thats', 'think', 'tidy', 'try', 'turn', 'type',\n",
       "       'username', 'utc', 'vandalism', 'vote', 'want', 'war', 'werent',\n",
       "       'wikipediagoodarticlenominationstransport', 'wonder', 'york'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = train_ds['comment_text']\n",
    "c1 = corpus.head(5)\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(c1)\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   ...  85  86  87  88  89  90  91  \\\n",
       "0   0   0   0   0   0   0   0   0   0   1  ...   1   0   1   1   0   0   1   \n",
       "1   0   0   0   0   1   0   0   0   0   0  ...   0   1   0   0   0   0   0   \n",
       "2   0   1   0   0   0   0   0   1   0   0  ...   0   0   0   0   0   1   0   \n",
       "3   1   0   1   1   0   1   1   0   0   0  ...   0   0   0   0   1   0   0   \n",
       "4   0   0   0   0   0   0   0   0   1   0  ...   0   0   0   0   0   0   0   \n",
       "\n",
       "   92  93  94  \n",
       "0   0   0   1  \n",
       "1   0   0   0  \n",
       "2   0   0   0  \n",
       "3   1   1   0  \n",
       "4   0   0   0  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(X.toarray())\n",
    "X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get TFIDF matrix as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.208745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.208745</td>\n",
       "      <td>0.208745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.208745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.208745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.132673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132673</td>\n",
       "      <td>0.132673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132673</td>\n",
       "      <td>0.132673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132673</td>\n",
       "      <td>0.132673</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.317869  0.000000  0.000000   \n",
       "2  0.000000  0.222236  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.132673  0.000000  0.132673  0.132673  0.000000  0.132673  0.132673   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         7         8         9   ...        85        86        87        88  \\\n",
       "0  0.000000  0.000000  0.208745  ...  0.208745  0.000000  0.208745  0.208745   \n",
       "1  0.000000  0.000000  0.000000  ...  0.000000  0.317869  0.000000  0.000000   \n",
       "2  0.222236  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.428411  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         89        90        91        92        93        94  \n",
       "0  0.000000  0.000000  0.208745  0.000000  0.000000  0.208745  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.222236  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.132673  0.000000  0.000000  0.132673  0.132673  0.000000  \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfTransform = TfidfTransformer()\n",
    "X_tfidf = tfidfTransform.fit_transform(X)\n",
    "X_tfidf = pd.DataFrame(X_tfidf.toarray())\n",
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pipelines for analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter dictionaries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* max_df: ignore terms that have a document frquency strictly higher than the given threshold  \n",
    "* min_df: ignore terms that have a document frequency strictly lower than the given threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for CountVectorizer()\n",
    "countvect_params = {\n",
    "    'count__min_df': [1, 3, 10, 20], \n",
    "    'count__max_df': [0.6, 0.8, 0.9, 1.0]\n",
    "    \n",
    "}\n",
    "\n",
    "# parameters for TfidfVectorizer()\n",
    "vectorizer_params = {\n",
    "    'vect__min_df': [1, 3, 10, 20], \n",
    "    'vect__max_df': [0.6, 0.8, 0.9, 1.0],\n",
    "    'vect__norm': ['l1','l2']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline using term counts and complimentary Naive Bayes\n",
    "pipe_CountVect_CompNB = Pipeline([\n",
    "    ('count', CountVectorizer()),\n",
    "    ('clf', ComplementNB())\n",
    "    ])\n",
    "\n",
    "# pipeline using Tfidf and complimentary Naive Bayes\n",
    "pipe_TfidfVect_CompNB = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    (\"clf\", ComplementNB())\n",
    "    ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset 2 run; using Term Counts, full instances, minus -1 test; using only 'toxic' comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search/ Randomized Search using TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    estimator = pipe_CountVect_CompNB,\n",
    "    param_distributions = countvect_params,\n",
    "    n_iter = 10,\n",
    "    random_state = 123,\n",
    "    n_jobs = 2,\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "count__max_df: 0.8\n",
      "count__min_df: 1\n",
      "Accuracy of the best parameters using the inner CV of the random search: 0.936\n",
      "Accuracy on test set: 0.888\n"
     ]
    }
   ],
   "source": [
    "random_search.fit(train_ds_subset2,train_labels_subset2)\n",
    "\n",
    "best_parameters = random_search.best_estimator_.get_params()\n",
    "for param_name in sorted(countvect_params.keys()):\n",
    "    print(f\"{param_name}: {best_parameters[param_name]}\")\n",
    "\n",
    "test_accuracy = random_search.score(test_ds_subset2, test_labels_subset2)\n",
    "print(\n",
    "    \"Accuracy of the best parameters using the inner CV of \"\n",
    "    f\"the random search: {random_search.best_score_:.3f}\"\n",
    ")\n",
    "print(f\"Accuracy on test set: {test_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count__max_df: 0.8\n",
      "count__min_df: 1\n",
      "Accuracy of the best parameters using the inner CV of the random search: 0.936\n",
      "Accuracy on test set: 0.888\n"
     ]
    }
   ],
   "source": [
    "best_parameters = random_search.best_estimator_.get_params()\n",
    "for param_name in sorted(countvect_params.keys()):\n",
    "    print(f\"{param_name}: {best_parameters[param_name]}\")\n",
    "\n",
    "test_accuracy = random_search.score(test_ds_subset2, test_labels_subset2)\n",
    "print(\n",
    "    \"Accuracy of the best parameters using the inner CV of \"\n",
    "    f\"the random search: {random_search.best_score_:.3f}\"\n",
    ")\n",
    "print(f\"Accuracy on test set: {test_accuracy:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset 2 run; using TFIDF, full instances, minus -1 test; using only 'toxic' comments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search/ Randomized Search using TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    estimator = pipe_TfidfVect,\n",
    "    param_distributions = vectorizer_params,\n",
    "    n_iter = 10,\n",
    "    random_state = 123,\n",
    "    n_jobs = 2,\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary of different subsets of the data\n",
    "subsets = {\n",
    "    'subset1': [train_ds_subset, train_labels_subset, test_ds_subset, test_labels_subset],\n",
    "        # filter: only 1000 instances per df\n",
    "        # filter: only 'toxic' labels used\n",
    "    'subset2': [train_ds_subset2, train_labels_subset2, test_ds_subset2, test_labels_subset2]\n",
    "        # filter: labels with -1 were removed from test set\n",
    "        # filter: only 'toxic' labels used\n",
    "}\n",
    "\n",
    "#list of parameter dictionaries\n",
    "parameters = [\n",
    "    countvect_params,\n",
    "    vectorizer_params\n",
    "    ]\n",
    "\n",
    "#list of different pipelines\n",
    "pipelines = [\n",
    "    pipe_CountVect_CompNB,\n",
    "    pipe_TfidfVect_CompNB\n",
    "    ]\n",
    "\n",
    "#pipeline with parameter dictionary\n",
    "pipe_parm_dict = {\n",
    "    'CountVect_CompNB': [pipe_CountVect_CompNB, countvect_params],\n",
    "    'TfidfVect_CompNB': [pipe_TfidfVect_CompNB, vectorizer_params]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_on_subset(pipe_params, subset):\n",
    "    'perform the pipeline(transform curpus to matrix and use to make model, use on test data) using the parameter dictionary on the data'\n",
    "\n",
    "    pipe, parameters = pipe_params\n",
    "    train_data, train_labels, test_data, test_labels = subset\n",
    "    \n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator = pipe,\n",
    "        param_distributions = parameters,\n",
    "        n_iter = 3,\n",
    "        random_state = 123,\n",
    "        n_jobs = 2,\n",
    "        verbose = 2   \n",
    "    )\n",
    "    print('Pipeline = {}'.format(pipe))\n",
    "    random_search.fit(train_data,train_labels)\n",
    "\n",
    "    best_parameters = random_search.best_estimator_.get_params()\n",
    "    print('Best parameters = ')\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(f\"{param_name}: {best_parameters[param_name]}\")\n",
    "\n",
    "    test_accuracy = random_search.score(test_data, test_labels)\n",
    "    print(\n",
    "        \"Accuracy of the best parameters using the inner CV of \"\n",
    "        f\"the random search: {random_search.best_score_:.3f}\"\n",
    "    )\n",
    "    print(f\"Accuracy on test set: {test_accuracy:.3f}\")\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline = Pipeline(steps=[('count', CountVectorizer()), ('clf', ComplementNB())])\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best parameters = \n",
      "count__max_df: 0.8\n",
      "count__min_df: 1\n",
      "Accuracy of the best parameters using the inner CV of the random search: 0.904\n",
      "Accuracy on test set: 0.390\n"
     ]
    }
   ],
   "source": [
    "run_on_subset(pipe_parm_dict['CountVect_CompNB'], subsets['subset1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline = Pipeline(steps=[('vect', TfidfVectorizer()), ('clf', ComplementNB())])\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best parameters = \n",
      "vect__max_df: 0.6\n",
      "vect__min_df: 10\n",
      "vect__norm: l2\n",
      "Accuracy of the best parameters using the inner CV of the random search: 0.808\n",
      "Accuracy on test set: 0.332\n"
     ]
    }
   ],
   "source": [
    "run_on_subset(pipe_parm_dict['TfidfVect_CompNB'], subsets['subset1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline = Pipeline(steps=[('count', CountVectorizer()), ('clf', ComplementNB())])\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best parameters = \n",
      "count__max_df: 0.8\n",
      "count__min_df: 1\n",
      "Accuracy of the best parameters using the inner CV of the random search: 0.936\n",
      "Accuracy on test set: 0.888\n"
     ]
    }
   ],
   "source": [
    "run_on_subset(pipe_parm_dict['CountVect_CompNB'], subsets['subset2'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d8c354d3cf95362cb56a9fc61661589ba752411f03c7f5d3fd3d8348f563371"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
